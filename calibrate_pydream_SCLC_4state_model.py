'''
Generated by pydream_it
PyDREAM run script for SCLC_popD_model.py
'''
from pydream.core import run_dream
from pysb.simulator import ScipyOdeSimulator
import numpy as np
from pydream.parameters import SampledParam
from pydream.convergence import Gelman_Rubin
from scipy.stats import norm,uniform
from four_state_sclc_NEv2toNonNE import model
#from four_state_sclc_NEv1toNonNE import model
import seaborn as sns
from matplotlib import pyplot as plt
import copy
from itertools import chain
import sys

import signal

class TimeoutException(RuntimeError):
    """ Time out occurred! """
    pass

def handler(signum, frame):
    print('forever is over!')
    raise TimeoutException()

# Register the signal function handler
signal.signal(signal.SIGALRM, handler)

# DREAM Settings
# Number of chains - should be at least 3.
nchains = 5
# Number of iterations
niterations = 80000

#Initialize PySB solver object for running simulations.  Simulation timespan should match experimental data.
#tspan = np.linspace(0,100, 101)
tspan = np.linspace(0,60,1001)
solver = ScipyOdeSimulator(model,integrator='lsoda',compiler='cython')
param_values = np.array([p.value for p in model.parameters])
parameters_idxs = list(np.arange(1,30))
rates_mask = np.concatenate((np.zeros(1,dtype=bool),np.ones(len(param_values[1:]),dtype=bool)))
log10_original_values = np.log10(param_values[rates_mask])
starts = []
for chain in range(nchains):
    start_position = log10_original_values + np.random.uniform(-0.25,0.25, size=np.shape(log10_original_values))
    starts.append(start_position)

# Not currently using
#def normalize(trajectory, trajectories):
#    """even though this is not really needed, if the data is already between 1 and 0!"""
#    """Rescale a matrix of model trajectories to 0-1"""
#    ymin = min([y for x in trajectories for y in x])
#    ymax = max([y for x in trajectories for y in x])
#    return (trajectory - ymin) / (ymax - ymin)

# USER must add commands to import/load any experimental data for use in the likelihood function!
TKO_pct = {
'NE_obs':0.670866848446898,
'NEv1_obs':0.001011170766988,
'NEv2_obs':0.294235217878072,
'NonNE_obs':0.033886762908045
}

TKO_stdev = {
'NE_obs':0.152576600276884,
'NEv1_obs':0.005730133430503,
'NEv2_obs':0.147927688661517,
'NonNE_obs':0.031684600453998
}

Oliver_pct = {
'NE_obs':0.259122843833646,
'NEv1_obs':0.318704767383416,
'NEv2_obs':0.010548327444441,
'NonNE_obs':0.411624061338496
}

Oliver_stdev = {
'NE_obs':0.171187022711461,
'NEv1_obs':0.157524233180492,
'NEv2_obs':0.016363538701013,
'NonNE_obs':0.223000331826237
}

like_pct_data = {}

obs_list = ['NE_obs','NEv1_obs','NEv2_obs','NonNE_obs']

#for obs in model.observables:
for obs in obs_list:
    like_pct_data[obs] = norm(loc=TKO_pct[obs],scale=TKO_stdev[obs])
#    like_pct_data[obs] = norm(loc=Oliver_pct[obs],scale=(Oliver_pct[obs]/10))

TOLERANCE = 1e-4
# USER must define a likelihood function!
def likelihood(position):
    Y=np.copy(position)
    param_values[rates_mask] = 10 ** Y
    signal.alarm(300)
    try:
        sim = solver.run(param_values=param_values,tspan=tspan).all
    except TimeoutException as exc:
        return -np.inf
    else:
        signal.alarm(0)
    all_lessthan1 = True
    for obs in obs_list:
        if sim[obs][-1] > 1:
            all_lessthan1 = False
    # if there aren't enough cells, or if the end of the sim gets to NaNs (because it grew too fast)
    if sim['total_cells'][-1] < 1000000:
        #print ('not enough cells ' + str(sim['total_cells'][-1]))
        return -np.inf
    elif np.isnan(sim['total_cells'][-1]):
        #print ('too many cells computer couldnt handle ' + str(sim['total_cells'][-1]))
        return -np.inf
    elif all_lessthan1: #smallest size in SCLC allografts (Lim et al) 1cm^3 (~10^8 cells), largest ~3.5cm^3 (~4*10^8)
        return np.inf*-1
    else:
        # get the percentages so you can check for equilibrium - first get the total # of cells
        cell_tot_run = np.zeros(len(tspan)) #do i need to do it this way? improve with sim['total_cells']?
        for obs in obs_list:
            for ind in range(len(tspan)):
                cell_tot_run[ind] = np.sum([cell_tot_run[ind],sim[obs][ind]],axis=0)
        # get the percentages so you can check for equilibrium
        sim_pct_run = {}
        for obs in obs_list:
            sim_pct_run[obs] = np.true_divide(sim[obs],cell_tot_run)
        # is it in equilibrium?
        not_eq = False
        y = np.column_stack((sim_pct_run['NE_obs'],sim_pct_run['NEv1_obs'],sim_pct_run['NEv2_obs'],sim_pct_run['NonNE_obs']))
        for idx in range(y.shape[1]):
            try:
                derivative = (y[:,idx][-1]-y[:,idx][-75])/(tspan[-1]-tspan[-75])
                if abs(derivative)>TOLERANCE:
                    not_eq = True
            except IndexError: # if tspan has less than 75 indices after the nanind process - not doing this anymore but leaving try/catch anyway...
                return -np.inf
                continue
        if not_eq:
            return -np.inf
        # Score
        total_cost = np.sum([like_pct_data[obs].logpdf(sim_pct_run[obs][-1]) for obs in obs_list[:-1]])
        if np.isnan(total_cost):
            total_cost = np.inf*-1
        return total_cost

sampled_params_list = list()

sp_k_NE_div_0 = SampledParam(norm, loc=np.log10(.428),scale=.25)
sampled_params_list.append(sp_k_NE_div_0)
sp_k_NE_div_x = SampledParam(norm, loc=np.log10(1.05),scale=1)
sampled_params_list.append(sp_k_NE_div_x)
sp_KD_Kx_NE_div = SampledParam(norm, loc=np.log10(1000),scale=1)
sampled_params_list.append(sp_KD_Kx_NE_div)

sp_k_NE_die_0 = SampledParam(norm, loc=np.log10(0.365),scale=.5)
sampled_params_list.append(sp_k_NE_die_0)
sp_k_NE_die_x = SampledParam(norm, loc=np.log10(0.95),scale=1)
sampled_params_list.append(sp_k_NE_die_x)
sp_KD_Kx_NE_die = SampledParam(norm, loc=np.log10(1000),scale=1)
sampled_params_list.append(sp_KD_Kx_NE_die)

sp_k_NEv1_div_0 = SampledParam(norm, loc=np.log10(.428),scale=.25)
sampled_params_list.append(sp_k_NEv1_div_0)
sp_k_NEv1_div_x = SampledParam(norm, loc=np.log10(1.05),scale=1)
sampled_params_list.append(sp_k_NEv1_div_x)
sp_KD_Kx_NEv1_div = SampledParam(norm, loc=np.log10(1000),scale=1)
sampled_params_list.append(sp_KD_Kx_NEv1_div)

sp_k_NEv1_die_0 = SampledParam(norm, loc=np.log10(0.365),scale=.5)
sampled_params_list.append(sp_k_NEv1_die_0)
sp_k_NEv1_die_x = SampledParam(norm, loc=np.log10(0.95),scale=1)
sampled_params_list.append(sp_k_NEv1_die_x)
sp_KD_Kx_NEv1_die = SampledParam(norm, loc=np.log10(1000),scale=1)
sampled_params_list.append(sp_KD_Kx_NEv1_die)

sp_k_NEv2_div_0 = SampledParam(norm, loc=np.log10(.428),scale=.25)
sampled_params_list.append(sp_k_NEv2_div_0)
sp_k_NEv2_div_x = SampledParam(norm, loc=np.log10(1.05),scale=1)
sampled_params_list.append(sp_k_NEv2_div_x)
sp_KD_Kx_NEv2_div = SampledParam(norm, loc=np.log10(1000),scale=1)
sampled_params_list.append(sp_KD_Kx_NEv2_div)

sp_k_NEv2_die_0 = SampledParam(norm, loc=np.log10(0.365),scale=.5)
sampled_params_list.append(sp_k_NEv2_die_0)
sp_k_NEv2_die_x = SampledParam(norm, loc=np.log10(0.95),scale=1)
sampled_params_list.append(sp_k_NEv2_die_x)
sp_KD_Kx_NEv2_die = SampledParam(norm, loc=np.log10(1000),scale=1)
sampled_params_list.append(sp_KD_Kx_NEv2_die)

sp_k_nonNE_div_0 = SampledParam(norm, loc=np.log10(.428),scale=.5)
sampled_params_list.append(sp_k_nonNE_div_0)
sp_k_nonNE_div_x = SampledParam(norm, loc=np.log10(0.95),scale=1)
sampled_params_list.append(sp_k_nonNE_div_x)
sp_KD_Kx_nonNE_div = SampledParam(norm, loc=np.log10(1000),scale=1)
sampled_params_list.append(sp_KD_Kx_nonNE_div)

sp_k_nonNe_die = SampledParam(norm, loc=np.log10(0.365),scale=.5)
sampled_params_list.append(sp_k_nonNe_die)

sp_kf_diff_ne_nev1 = SampledParam(uniform, loc=np.log10(0.05),scale=2.5)
sampled_params_list.append(sp_kf_diff_ne_nev1)
sp_kr_diff_ne_nev1 = SampledParam(uniform, loc=np.log10(0.05),scale=2.5)
sampled_params_list.append(sp_kr_diff_ne_nev1)

sp_kf_diff_ne_nev2 = SampledParam(uniform, loc=np.log10(0.05),scale=2.5)
sampled_params_list.append(sp_kf_diff_ne_nev2)
sp_kr_diff_ne_nev2 = SampledParam(uniform, loc=np.log10(0.05),scale=2.5)
sampled_params_list.append(sp_kr_diff_ne_nev2)

sp_kf_diff_nev1_nev2 = SampledParam(uniform, loc=np.log10(0.05),scale=2.5)
sampled_params_list.append(sp_kf_diff_nev1_nev2)
sp_kr_diff_nev1_nev2 = SampledParam(uniform, loc=np.log10(0.05),scale=2.5)
sampled_params_list.append(sp_kr_diff_nev1_nev2)

sp_kf_diff_nev2_nonNe = SampledParam(uniform, loc=np.log10(0.05),scale=2.5)
sampled_params_list.append(sp_kf_diff_nev2_nonNe)

converged = False
sampled_params, log_ps = run_dream(parameters=sampled_params_list,
                                   likelihood=likelihood,
                                   niterations=niterations,
                                   nchains=nchains,
                                   start=starts,
                                   multitry=False,
                                   gamma_levels=6,
                                   nCR=6,
                                   p_gamma_unity=0.5,
                                   adapt_gamma=True,
                                   history_thin=1,
                                   model_name='dreamzs_5chain_NEv2_Sage_NM',
                                   verbose=True)
total_iterations = niterations
# Save sampling output (sampled parameter values and their corresponding logps).
for chain in range(len(sampled_params)):
    np.save('dreamzs_5chain_NEv2_Sage_NM_sampled_params_chain_' + str(chain)+'_'+str(total_iterations), sampled_params[chain])
    np.save('dreamzs_5chain_NEv2_Sage_NM_logps_chain_' + str(chain)+'_'+str(total_iterations), log_ps[chain])

GR = Gelman_Rubin(sampled_params)
print('At iteration: ',total_iterations,' GR = ',GR)
np.savetxt('dreamzs_5chain_NEv2_Sage_NM_GelmanRubin_iteration_'+str(total_iterations)+'.txt', GR)
old_samples = sampled_params

if np.any(GR>1.2):
    while not converged:
        starts = [old_samples[chain][-1, :] for chain in range(nchains)]
        total_iterations += niterations
        sampled_params, log_ps = run_dream(parameters=sampled_params_list,
                                           likelihood=likelihood,
                                           niterations=niterations,
                                           nchains=nchains,
                                           start=starts,
                                           multitry=False,
                                           gamma_levels=6,
                                           nCR=6,
                                           p_gamma_unity=0.5,
                                           adapt_gamma=True,
                                           history_thin=1,
                                           model_name='dreamzs_5chain_NEv2_Sage_NM',
                                           verbose=True,
                                           restart=True)
        for chain in range(len(sampled_params)):
            np.save('dreamzs_5chain_NEv2_Sage_NM_sampled_params_chain_' + str(chain)+'_'+str(total_iterations), sampled_params[chain])
            np.save('dreamzs_5chain_NEv2_Sage_NM_logps_chain_' + str(chain)+'_'+str(total_iterations), log_ps[chain])
        old_samples = [np.concatenate((old_samples[chain], sampled_params[chain])) for chain in range(nchains)]
        GR = Gelman_Rubin(old_samples)
        print('At iteration: ',total_iterations,' GR = ',GR)
        np.savetxt('dreamzs_5chain_NEv2_Sage_NM_GelmanRubin_iteration_' + str(total_iterations)+'.txt', GR)
        if np.all(GR<1.2):
            converged = True